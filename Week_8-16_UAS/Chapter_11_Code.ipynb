{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 11 - Training Deep Neural Networks Code Reproduction"
      ],
      "metadata": {
        "id": "GfRhVBxtCGGo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BXIM2w2jB7wh"
      },
      "outputs": [],
      "source": [
        "# Impor umum\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Konfigurasi plot\n",
        "%matplotlib inline\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh penggunaan inisialisasi He\n",
        "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "\n",
        "# Contoh penggunaan inisialisasi LeCun (untuk aktivasi SELU)\n",
        "keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9sVlanfD5I1",
        "outputId": "f0be0c14-820d-4c9c-cb96-29cc1a7ae306"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Dense name=dense_1, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan LeakyReLU sebagai layer terpisah\n",
        "model = keras.models.Sequential([\n",
        "    # ... (layer sebelumnya)\n",
        "    keras.layers.Dense(10),\n",
        "    keras.layers.LeakyReLU(alpha=0.2), # alpha adalah hyperparameter\n",
        "    # ... (layer selanjutnya)\n",
        "])\n",
        "\n",
        "# Menggunakan SELU\n",
        "# Untuk self-normalization, gunakan aktivasi 'selu' dan inisialisasi 'lecun_normal'\n",
        "layer_selu = keras.layers.Dense(10, activation=\"selu\",\n",
        "                                kernel_initializer=\"lecun_normal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDtS9KCrD62R",
        "outputId": "59330774-ac25-4df9-b4ca-8bea336ed3de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membangun model dengan Batch Normalization\n",
        "model_bn = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Menampilkan ringkasan model untuk melihat layer BN\n",
        "model_bn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "cK_zNSxkD8CK",
        "outputId": "527df4d3-7590-494e-dff0-3c028b2c0798"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │         \u001b[38;5;34m3,136\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │         \u001b[38;5;34m1,200\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m271,346\u001b[0m (1.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,346</span> (1.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m268,978\u001b[0m (1.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,978</span> (1.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,368\u001b[0m (9.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> (9.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengatur clipvalue pada optimizer\n",
        "optimizer_clipval = keras.optimizers.SGD(clipvalue=1.0)\n",
        "# model.compile(loss=\"...\", optimizer=optimizer_clipval)\n",
        "\n",
        "# Mengatur clipnorm pada optimizer\n",
        "optimizer_clipnorm = keras.optimizers.SGD(clipnorm=1.0)\n",
        "# model.compile(loss=\"...\", optimizer=optimizer_clipnorm)"
      ],
      "metadata": {
        "id": "xPOwxVo_D9z3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset Fashion MNIST\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Membagi dan melakukan scaling data\n",
        "# Dataset A untuk model pre-trained, Dataset B untuk transfer learning\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Membagi data menjadi dataset A (item 0-4) dan B (item 5-9)\n",
        "def split_dataset(X, y):\n",
        "    y_5_or_less = (y < 5)\n",
        "    y_6_or_more = (y >= 5)\n",
        "    return (X[y_5_or_less], y[y_5_or_less]), \\\n",
        "           (X[y_6_or_more], y[y_6_or_more] - 5)\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "\n",
        "# 1. Melatih model A pada dataset A\n",
        "model_A = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(5, activation=\"softmax\")\n",
        "])\n",
        "model_A.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1e-3), metrics=[\"accuracy\"])\n",
        "# history_A = model_A.fit(X_train_A, y_train_A, epochs=20, validation_data=(X_valid_A, y_valid_A))\n",
        "# model_A.save(\"my_model_A.h5\") # Simpan model A\n",
        "\n",
        "\n",
        "# 2. Membuat model B yang menggunakan kembali layer dari model A\n",
        "# model_A = keras.models.load_model(\"my_model_A.h5\") # Muat kembali model A\n",
        "model_A_clone = keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())\n",
        "\n",
        "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1]) # Ambil semua layer kecuali output layer\n",
        "model_B_on_A.add(keras.layers.Dense(5, activation=\"softmax\")) # Tambahkan output layer baru untuk dataset B\n",
        "\n",
        "# 3. Membekukan (freeze) layer yang digunakan kembali\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 4. Melatih model B (hanya melatih output layer baru)\n",
        "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "                     metrics=[\"accuracy\"])\n",
        "# history_B = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))\n",
        "\n",
        "# 5. Fine-tuning: membuka kembali layer dan melatih dengan learning rate rendah\n",
        "for layer in model_B_on_A.layers[:-1]:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-4) # learning rate sangat kecil\n",
        "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "history_fine_tune = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))\n",
        "\n",
        "evaluasi = model_B_on_A.evaluate(X_test_B, y_test_B)\n",
        "print(\"\\nHasil evaluasi setelah fine-tuning:\", evaluasi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6biLYnyLD_Bw",
        "outputId": "2b8dda95-c43f-435c-840f-8e18ee52626d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.4787 - loss: 1.3808 - val_accuracy: 0.7530 - val_loss: 0.9531\n",
            "Epoch 2/4\n",
            "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.8950 - val_accuracy: 0.8007 - val_loss: 0.7474\n",
            "Epoch 3/4\n",
            "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7977 - loss: 0.7197 - val_accuracy: 0.8208 - val_loss: 0.6425\n",
            "Epoch 4/4\n",
            "\u001b[1m860/860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.6263 - val_accuracy: 0.8396 - val_loss: 0.5765\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.5848\n",
            "\n",
            "Hasil evaluasi setelah fine-tuning: [0.5801527500152588, 0.8276000022888184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Momentum optimization\n",
        "optimizer_momentum = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "\n",
        "# Nesterov Accelerated Gradient\n",
        "optimizer_nesterov = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "\n",
        "# AdaGrad\n",
        "optimizer_adagrad = keras.optimizers.Adagrad(learning_rate=0.001)\n",
        "\n",
        "# RMSProp\n",
        "optimizer_rmsprop = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
        "\n",
        "# Adam\n",
        "optimizer_adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "mCcHClfeEj8V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### 7.1 Power Scheduling\n",
        "# lr = lr0 / (1 + steps / s)**c. Di Keras, c=1 dan s = 1/decay.\n",
        "optimizer_power = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)\n",
        "\n",
        "# ### 7.2 Exponential Scheduling\n",
        "def exponential_decay_fn(epoch):\n",
        "    return 0.01 * 0.1**(epoch / 20)\n",
        "\n",
        "# Cara 1: Menggunakan fungsi dan callback LearningRateScheduler\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "# history = model.fit(..., callbacks=[lr_scheduler])\n",
        "\n",
        "# ### 7.3 Piecewise Constant Scheduling\n",
        "def piecewise_constant_fn(epoch):\n",
        "    if epoch < 5:\n",
        "        return 0.01\n",
        "    elif epoch < 15:\n",
        "        return 0.005\n",
        "    else:\n",
        "        return 0.001\n",
        "\n",
        "lr_scheduler_piecewise = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
        "# history = model.fit(..., callbacks=[lr_scheduler_piecewise])\n",
        "\n",
        "\n",
        "# ### 7.4 Performance Scheduling\n",
        "# Mengurangi learning rate ketika validation loss berhenti membaik\n",
        "lr_scheduler_perf = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "# history = model.fit(..., callbacks=[lr_scheduler_perf])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H2lR-LPElVu",
        "outputId": "fe55dc20-362f-417b-de47-3220becf2971"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}