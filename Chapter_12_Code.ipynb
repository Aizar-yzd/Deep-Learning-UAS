{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 12 - Custom Models and Training with TensorFlow Code Reproduction"
      ],
      "metadata": {
        "id": "x1-dNUPpWuKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impor umum\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "MteeXoEsWt62"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1WdIJlKWj6c",
        "outputId": "94a7df7c-4d1b-4213-aea3-8019ff0450f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor t:\n",
            " tf.Tensor(\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
            "\n",
            "Indexing t[:, 1:]:\n",
            " tf.Tensor(\n",
            "[[2. 3.]\n",
            " [5. 6.]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "Operasi t + 10:\n",
            " tf.Tensor(\n",
            "[[11. 12. 13.]\n",
            " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
            "Operasi tf.square(t):\n",
            " tf.Tensor(\n",
            "[[ 1.  4.  9.]\n",
            " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n",
            "Perkalian matriks t @ tf.transpose(t):\n",
            " tf.Tensor(\n",
            "[[14. 32.]\n",
            " [32. 77.]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "Konversi dari NumPy ke Tensor: tf.Tensor([2. 4. 5.], shape=(3,), dtype=float64)\n",
            "Konversi dari Tensor ke NumPy: [[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "\n",
            "Variabel TensorFlow:\n",
            " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)>\n",
            "Variabel setelah v.assign(2 * v):\n",
            " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 2.,  4.,  6.],\n",
            "       [ 8., 10., 12.]], dtype=float32)>\n",
            "Variabel setelah v[0, 1].assign(42):\n",
            " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[ 2., 42.,  6.],\n",
            "       [ 8., 10., 12.]], dtype=float32)>\n"
          ]
        }
      ],
      "source": [
        "# Membuat Tensor\n",
        "t = tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix\n",
        "print(\"Tensor t:\\n\", t)\n",
        "\n",
        "# Indexing\n",
        "print(\"\\nIndexing t[:, 1:]:\\n\", t[:, 1:])\n",
        "\n",
        "# Operasi\n",
        "print(\"\\nOperasi t + 10:\\n\", t + 10)\n",
        "print(\"Operasi tf.square(t):\\n\", tf.square(t))\n",
        "print(\"Perkalian matriks t @ tf.transpose(t):\\n\", t @ tf.transpose(t))\n",
        "\n",
        "# Interoperabilitas dengan NumPy\n",
        "a = np.array([2., 4., 5.])\n",
        "print(\"\\nKonversi dari NumPy ke Tensor:\", tf.constant(a))\n",
        "print(\"Konversi dari Tensor ke NumPy:\", t.numpy())\n",
        "\n",
        "# Variabel TensorFlow\n",
        "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "print(\"\\nVariabel TensorFlow:\\n\", v)\n",
        "\n",
        "# Mengubah nilai Variabel\n",
        "v.assign(2 * v)\n",
        "print(\"Variabel setelah v.assign(2 * v):\\n\", v)\n",
        "v[0, 1].assign(42)\n",
        "print(\"Variabel setelah v[0, 1].assign(42):\\n\", v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss  = tf.abs(error) - 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)"
      ],
      "metadata": {
        "id": "f2IO8qjcb1ac"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi aktivasi kustom (softplus)\n",
        "def my_softplus(z):\n",
        "    return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "# Inisialisasi kernel kustom\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "# Regularizer L1 kustom\n",
        "def my_l1_regularizer(weights):\n",
        "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "# Penggunaan komponen kustom dalam sebuah layer\n",
        "# layer = keras.layers.Dense(1, activation=my_softplus,\n",
        "#                            kernel_initializer=my_glorot_initializer,\n",
        "#                            kernel_regularizer=my_l1_regularizer)"
      ],
      "metadata": {
        "id": "PIDn3B4Kb2bA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDense(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        # Membuat bobot (weights)\n",
        "        self.kernel = self.add_weight(\n",
        "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
        "            initializer=\"glorot_uniform\")\n",
        "        self.bias = self.add_weight(\n",
        "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, X):\n",
        "        # Logika forward pass\n",
        "        return self.activation(X @ self.kernel + self.bias)"
      ],
      "metadata": {
        "id": "vH_VWcFab3yW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
        "                                          kernel_initializer=\"he_normal\")\n",
        "                       for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return inputs + Z # Koneksi residual\n",
        "\n",
        "class ResidualRegressor(keras.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
        "        self.block1 = ResidualBlock(2, 30)\n",
        "        self.block2 = ResidualBlock(2, 30)\n",
        "        self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.hidden1(inputs)\n",
        "        for _ in range(1 + 3): # Loop untuk membuat model lebih dalam\n",
        "            Z = self.block1(Z)\n",
        "        Z = self.block2(Z)\n",
        "        return self.out(Z)"
      ],
      "metadata": {
        "id": "xX4iou19b6UL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung gradien dari f(x) = x^2\n",
        "w = tf.Variable(5.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = w ** 2\n",
        "\n",
        "dz_dw = tape.gradient(z, w)\n",
        "print(\"\\nGradien z terhadap w:\", dz_dw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYeZJ2Dxb60S",
        "outputId": "0660dccf-1f4e-496d-fd44-624a1594ac16"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gradien z terhadap w: tf.Tensor(10.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyiapkan data dan model sederhana\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Menyiapkan komponen pelatihan\n",
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# Loop pelatihan kustom\n",
        "print(\"\\nMemulai Loop Pelatihan Kustom:\")\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
        "    for step in range(1, n_steps + 1):\n",
        "        # Mengambil satu batch data\n",
        "        X_batch, y_batch = X_train[(step-1)*batch_size:step*batch_size], y_train[(step-1)*batch_size:step*batch_size]\n",
        "\n",
        "        # Membuka GradientTape\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch, training=True)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model.losses) # Menambahkan loss regularisasi\n",
        "\n",
        "        # Menghitung dan menerapkan gradien\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnaXxh_QcGuB",
        "outputId": "9b6044ef-b240-4a65-d608-257d3a312127"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Memulai Loop Pelatihan Kustom:\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi Python biasa\n",
        "def cube(x):\n",
        "    return x ** 3\n",
        "print(\"\\nHasil cube(2):\", cube(2))\n",
        "\n",
        "# Mengubahnya menjadi TensorFlow Function\n",
        "tf_cube = tf.function(cube)\n",
        "print(\"Hasil tf_cube(2):\", tf_cube(2))\n",
        "\n",
        "# Menggunakan decorator (cara yang lebih umum)\n",
        "@tf.function\n",
        "def tf_cube_decorated(x):\n",
        "    return x ** 3\n",
        "\n",
        "print(\"Hasil tf_cube_decorated(2):\", tf_cube_decorated(2))\n",
        "\n",
        "# Melihat kode yang dihasilkan oleh AutoGraph\n",
        "print(\"\\nKode yang dihasilkan AutoGraph:\")\n",
        "print(tf.autograph.to_code(tf_cube_decorated.python_function))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KEMRsfJcHLL",
        "outputId": "c01dd812-8608-462a-c783-76ec8c4f3924"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hasil cube(2): 8\n",
            "Hasil tf_cube(2): tf.Tensor(8, shape=(), dtype=int32)\n",
            "Hasil tf_cube_decorated(2): tf.Tensor(8, shape=(), dtype=int32)\n",
            "\n",
            "Kode yang dihasilkan AutoGraph:\n",
            "def tf__tf_cube_decorated(x):\n",
            "    with ag__.FunctionScope('tf_cube_decorated', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = ag__.ld(x) ** 3\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}